{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27eb8db5-866a-4103-bda3-25cc33e0f6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7a98ead-9cdc-4022-8b8e-3e9c65a92f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\anpar\\Python\\Pandas\\Classification_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "142f6277-0895-4c0e-bd3e-2d15b609542c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, 1:]\n",
    "y = df.iloc[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7985e2d4-88c9-44b6-9605-7267c964ef99",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Standarize:\n",
    "    \n",
    "    mean = std = None\n",
    "    \n",
    "    def fit(self, X):\n",
    "        self.mean = X.mean(axis=0) + 1e-30\n",
    "        self.std = X.std(axis=0) + 1e-30\n",
    "        \n",
    "        \n",
    "    def fit_transform(self, X):\n",
    "        self.fit(X)\n",
    "        X_scaled = (X - self.mean)/self.std\n",
    "        return X_scaled\n",
    "        \n",
    "\n",
    "    def transform(self, X):\n",
    "        try:\n",
    "            X_scaled = (X - self.mean)/self.std\n",
    "            return X_scaled\n",
    "        except TypeError:\n",
    "            raise TypeError('No data has been provided to calculate mean and standard deviation')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c8d8d87-e379-4243-9104-9cfee1149418",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_desc(X, y, learning_rate=0.01, n_iterations=100):\n",
    "    m, n = X.shape\n",
    "    w = np.zeros(n)\n",
    "    \n",
    "    for i in range(1, n_iterations+1):\n",
    "        \n",
    "        z = X.dot(w)\n",
    "        y_pred = sigmoid(z)\n",
    "        w += learning_rate*(y - y_pred).T.dot(X)/m\n",
    "        \n",
    "        if i%10 == 0:\n",
    "            loss_func = -np.mean(y * np.log(y_pred + 1e-8) + (1 - y) * np.log(1 - y_pred + 1e-8))/m\n",
    "            print(f'{i}th iteration done. Loss = {loss_func}')\n",
    "\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3dc6ea3d-5a6f-48c2-8524-e9a774535075",
   "metadata": {},
   "outputs": [],
   "source": [
    "def step(z):\n",
    "    return 1 if z >= 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7573b538-912d-44a0-bd3d-85ee13e7a797",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1/(1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "619c9e93-5dea-494d-8ea8-f65b8304b02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoding(y):\n",
    "    classes = np.unique(y)\n",
    "    y_encoded = np.zeros(y.shape[0])\n",
    "    \n",
    "    for i in classes:\n",
    "        y_df = pd.DataFrame(y).loc[y == i].copy()\n",
    "        y_n = pd.DataFrame(np.zeros(y.shape[0]))\n",
    "        y_n.loc[y_df.index] = 1\n",
    "        y_encoded = np.c_[y_encoded, y_n]\n",
    "    \n",
    "    y_encoded = np.delete(y_encoded, 0, 1)\n",
    "    \n",
    "    return y_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c8be34b-c482-4d50-8a6e-5e31a730e7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_accuracy(y_test, y_preds):\n",
    "    m, n = y_test.shape\n",
    "    y_total = m*n\n",
    "    \n",
    "    y_bool = (y_test == y_preds)\n",
    "    y_correct = np.count_nonzero(y_bool == True)\n",
    "    \n",
    "    accuracy = y_correct/y_total\n",
    "    return accuracy\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a5656e3-a972-4d12-958c-39e15191bc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression:\n",
    "    def fit(self, X_train, y_train, learning_rate=0.01, n_iterations=100):\n",
    "        self.w_s = np.zeros((X_train.shape[1], 1))\n",
    "        for k in range(y_train.shape[1]):\n",
    "            y_train_col = y_train[:, k]\n",
    "            w = grad_desc(X_train, y_train_col, learning_rate=learning_rate, n_iterations=n_iterations)\n",
    "            self.w_s = np.insert(self.w_s, -1, w, axis=1)\n",
    "            print(w.shape)\n",
    "        self.w_s = np.delete(self.w_s, -1, axis=1)\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        step_brute = np.vectorize(step)\n",
    "        self.y_pred = step_brute(X_test.dot(self.w_s))\n",
    "        return self.y_pred\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5671e045-b977-4d0c-aa1f-ef4c4d2a44e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iterations = 100\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7dc1ae45-8a73-4d04-8497-b2fc4c93a655",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scalar = Standarize()\n",
    "# X = scalar.fit_transform(X)\n",
    "# X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "75d585ca-280d-4e4b-a41d-b11b4228278b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.insert(X, 0, 1, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e81e6452-d2d5-42c2-85b3-182182743bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_en = one_hot_encoding(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ab8d49c7-7ed3-4664-b186-be9898070575",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train, y_train = np.array(X[:int(0.8*X.shape[0]), :]), np.array(y_en[:int(0.8*X.shape[0]), :])\n",
    "X_test, y_test = np.array(X[int(0.8*X.shape[0]):, :]), np.array(y_en[int(0.8*X.shape[0]):, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fe9cb047-9afb-4a1f-a36d-f4b528847e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = np.array(y_en[int(0.8*X.shape[0]):, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "61c63ebe-cfea-4885-80a8-d13276a938fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anpar\\AppData\\Local\\Temp\\ipykernel_34780\\3692174223.py:2: RuntimeWarning: overflow encountered in exp\n",
      "  return 1/(1 + np.exp(-z))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10th iteration done. Loss = 6.644538851324608e-05\n",
      "20th iteration done. Loss = 1.5020458236913031e-05\n",
      "30th iteration done. Loss = 1.2852618429357496e-05\n",
      "40th iteration done. Loss = 1.1304249506245099e-05\n",
      "50th iteration done. Loss = 9.94541772251843e-06\n",
      "60th iteration done. Loss = 8.708848263713403e-06\n",
      "70th iteration done. Loss = 7.86065231314471e-06\n",
      "80th iteration done. Loss = 7.463389796119461e-06\n",
      "90th iteration done. Loss = 7.306250630435708e-06\n",
      "100th iteration done. Loss = 7.151933636748867e-06\n",
      "(785,)\n",
      "10th iteration done. Loss = 1.535388754712788e-05\n",
      "20th iteration done. Loss = 9.438622399992688e-06\n",
      "30th iteration done. Loss = 7.186748315913477e-06\n",
      "40th iteration done. Loss = 5.742339000272253e-06\n",
      "50th iteration done. Loss = 5.056572442347027e-06\n",
      "60th iteration done. Loss = 4.799619333593884e-06\n",
      "70th iteration done. Loss = 4.525237869081727e-06\n",
      "80th iteration done. Loss = 4.102305720546987e-06\n",
      "90th iteration done. Loss = 3.6971191473632825e-06\n",
      "100th iteration done. Loss = 3.3902692642561977e-06\n",
      "(785,)\n",
      "10th iteration done. Loss = 6.495492179993737e-06\n",
      "20th iteration done. Loss = 4.203230437794301e-06\n",
      "30th iteration done. Loss = 3.3522463344101456e-06\n",
      "40th iteration done. Loss = 2.978602397745048e-06\n",
      "50th iteration done. Loss = 2.715939641508406e-06\n",
      "60th iteration done. Loss = 2.3744332495901633e-06\n",
      "70th iteration done. Loss = 2.038919143710098e-06\n",
      "80th iteration done. Loss = 1.6693508186688966e-06\n",
      "90th iteration done. Loss = 1.5195374709101513e-06\n",
      "100th iteration done. Loss = 1.3697127345958017e-06\n",
      "(785,)\n",
      "10th iteration done. Loss = 2.2093005868039565e-05\n",
      "20th iteration done. Loss = 1.7849222196532327e-05\n",
      "30th iteration done. Loss = 1.625566653452383e-05\n",
      "40th iteration done. Loss = 1.4531338812854754e-05\n",
      "50th iteration done. Loss = 2.3140136734463265e-05\n",
      "60th iteration done. Loss = 1.576669177411215e-05\n",
      "70th iteration done. Loss = 1.3392922287691722e-05\n",
      "80th iteration done. Loss = 1.8743117150698556e-05\n",
      "90th iteration done. Loss = 1.581764351946114e-05\n",
      "100th iteration done. Loss = 1.3288059344733133e-05\n",
      "(785,)\n",
      "10th iteration done. Loss = 1.5033970883803496e-05\n",
      "20th iteration done. Loss = 1.2447032857833162e-05\n",
      "30th iteration done. Loss = 1.0458382985843169e-05\n",
      "40th iteration done. Loss = 9.315781870440463e-06\n",
      "50th iteration done. Loss = 8.403916730504285e-06\n",
      "60th iteration done. Loss = 7.707644123869901e-06\n",
      "70th iteration done. Loss = 7.307056096214892e-06\n",
      "80th iteration done. Loss = 7.0207207373557595e-06\n",
      "90th iteration done. Loss = 6.667422188509855e-06\n",
      "100th iteration done. Loss = 6.420137944830633e-06\n",
      "(785,)\n",
      "10th iteration done. Loss = 1.9468030629262223e-05\n",
      "20th iteration done. Loss = 1.6442234921224498e-05\n",
      "30th iteration done. Loss = 1.4453946374856552e-05\n",
      "40th iteration done. Loss = 1.3999877996680269e-05\n",
      "50th iteration done. Loss = 1.4472953558060654e-05\n",
      "60th iteration done. Loss = 1.3757506100302482e-05\n",
      "70th iteration done. Loss = 1.702714093699952e-05\n",
      "80th iteration done. Loss = 1.544915616827049e-05\n",
      "90th iteration done. Loss = 9.296170427391245e-06\n",
      "100th iteration done. Loss = 8.65380795476362e-06\n",
      "(785,)\n",
      "10th iteration done. Loss = 2.2591450473730188e-05\n",
      "20th iteration done. Loss = 1.440029353294638e-05\n",
      "30th iteration done. Loss = 1.178461437714476e-05\n",
      "40th iteration done. Loss = 1.0654098321375128e-05\n",
      "50th iteration done. Loss = 9.64674772811404e-06\n",
      "60th iteration done. Loss = 9.096690882694879e-06\n",
      "70th iteration done. Loss = 8.24737556924057e-06\n",
      "80th iteration done. Loss = 8.709061529165044e-06\n",
      "90th iteration done. Loss = 8.32845732109261e-06\n",
      "100th iteration done. Loss = 7.802779758729681e-06\n",
      "(785,)\n",
      "10th iteration done. Loss = 3.057780997934189e-05\n",
      "20th iteration done. Loss = 1.999207933942376e-05\n",
      "30th iteration done. Loss = 5.6411021440177446e-05\n",
      "40th iteration done. Loss = 1.746813236622034e-05\n",
      "50th iteration done. Loss = 1.564907553643953e-05\n",
      "60th iteration done. Loss = 2.293671669373622e-05\n",
      "70th iteration done. Loss = 2.873521657310645e-05\n",
      "80th iteration done. Loss = 1.4571847285436337e-05\n",
      "90th iteration done. Loss = 1.3458084865752721e-05\n",
      "100th iteration done. Loss = 1.4593627095577188e-05\n",
      "(785,)\n",
      "10th iteration done. Loss = 1.4642836742968555e-05\n",
      "20th iteration done. Loss = 9.09511648197291e-06\n",
      "30th iteration done. Loss = 7.028539086190273e-06\n",
      "40th iteration done. Loss = 6.043338999592254e-06\n",
      "50th iteration done. Loss = 5.3415455256954025e-06\n",
      "60th iteration done. Loss = 4.833919790750099e-06\n",
      "70th iteration done. Loss = 4.474077344090803e-06\n",
      "80th iteration done. Loss = 4.1109238361212404e-06\n",
      "90th iteration done. Loss = 3.88770700777749e-06\n",
      "100th iteration done. Loss = 3.6463841009872286e-06\n",
      "(785,)\n",
      "10th iteration done. Loss = 1.0698098227340742e-05\n",
      "20th iteration done. Loss = 8.012588912018688e-06\n",
      "30th iteration done. Loss = 6.800111700701698e-06\n",
      "40th iteration done. Loss = 6.407891574497366e-06\n",
      "50th iteration done. Loss = 6.062257582880205e-06\n",
      "60th iteration done. Loss = 5.4159923591798296e-06\n",
      "70th iteration done. Loss = 5.11891225740086e-06\n",
      "80th iteration done. Loss = 4.7567932118033286e-06\n",
      "90th iteration done. Loss = 4.454002115573245e-06\n",
      "100th iteration done. Loss = 4.240484731997184e-06\n",
      "(785,)\n"
     ]
    }
   ],
   "source": [
    "regressor = LogisticRegression()\n",
    "w_s = regressor.fit(X_train, y_train, n_iterations=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cb591e53-b506-41cd-916b-848490a6aa5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "92ea9c15-db22-494a-a0f0-280c0df68f21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 1, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 1],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 1]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b745ce1c-d8d8-4b19-b273-cd5f3f5a8f41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5af4540d-fab9-4480-8fdd-6af532663a31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9866"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_accuracy(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "de4dea3a-97da-4a3b-ac72-8cff1fe4523e",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.read_csv(r\"C:\\Users\\anpar\\Python\\ML_Bootcamp_Aadi\\Algo\\Test_Datasets\\Classification_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "141ad8db-a6cc-4867-9a2b-1e25ebcd6379",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = new_df.iloc[:, 1:]\n",
    "X_new = np.insert(X_new, 0, 1, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6d6ba8d8-0e61-4fd2-a046-f98478eba242",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_en = regressor.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "66565d35-8f5f-4060-836a-3ae8d23b2fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_new = np.argmax(y_en, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "63cb6c02-69f8-4904-be77-0af474e9f551",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = np.insert(new_df, 1, y_new, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8afaf0cf-b6d8-466d-bea3-43ead976aec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_df = pd.DataFrame(new_df, columns=['ID']+['label']+['pixel'+str(i) for i in range(784)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5c84cb41-6b47-4f3e-bd7f-9c11ac8a61b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_df.to_csv(r\"C:\\Users\\anpar\\Python\\ML_Bootcamp_Aadi\\Algo\\Test_Datasets\\Labeled_Logistic_Classification_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8a9e45-d842-4c35-b945-11235dc8d000",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
